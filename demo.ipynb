{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de95feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1beea259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get User Input\n",
    "user_query = input(\"What would you like to research? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8677eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # load .env file\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6396039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70bb55a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: impact of AI on climate change\n",
      "Generated queries:\n",
      "1. impact of AI on climate change\n",
      "2. \"Artificial intelligence applications for reducing greenhouse gas emissions\"\n",
      "3. \"How AI technologies influence climate change mitigation strategies\"\n",
      "4. \"Environmental risks and ethical concerns of AI deployment in climate policy\"\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate Search Queries with Groq's API\n",
    "\n",
    "def generate_search_queries(user_query, num_queries=3):\n",
    "    \"\"\"\n",
    "    Generates multiple search queries based on the user's original query\n",
    "    to ensure comprehensive research coverage using Groq's API.\n",
    "    \"\"\"\n",
    "    # Initialize Groq client\n",
    "    client = Groq()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a research assistant. Your task is to generate {num_queries} different search queries \n",
    "    based on the user's original query. These queries should cover different aspects, perspectives, \n",
    "    or related topics to ensure comprehensive research coverage.\n",
    "    \n",
    "    Original query: \"{user_query}\"\n",
    "    \n",
    "    Generate {num_queries} search queries as a numbered list without any additional text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Call Groq API\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"openai/gpt-oss-120b\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful research assistant.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "            top_p=1,\n",
    "            reasoning_effort=\"medium\",\n",
    "            stream=False,\n",
    "            stop=None\n",
    "        )\n",
    "        # Extract the generated queries from the response\n",
    "        generated_text = completion.choices[0].message.content.strip()\n",
    "\n",
    "        # Parse the numbered list into a Python list\n",
    "        queries = []\n",
    "        for line in generated_text.split(\"\\n\"):\n",
    "            if \". \" in line:\n",
    "                # Extract the query text after the number\n",
    "                query_text = line.split(\". \", 1)[1].strip()\n",
    "                queries.append(query_text)\n",
    "        \n",
    "        # Include the original query as well\n",
    "        queries.insert(0, user_query)\n",
    "        \n",
    "        return queries[:num_queries+1]  # Return original + generated queries\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating search queries: {e}\")\n",
    "        # Fallback: return the original query only\n",
    "        return [user_query]\n",
    "    \n",
    "test_query = \"impact of AI on climate change\"\n",
    "generated_queries = generate_search_queries(test_query)\n",
    "print(\"Original query:\", test_query)\n",
    "print(\"Generated queries:\")\n",
    "for i, query in enumerate(generated_queries):\n",
    "    print(f\"{i+1}. {query}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-research-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
